{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d240bc47-8316-4427-aea9-eb38df8f322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from chromatic import *\n",
    "import rainbowconnection\n",
    "import astropy.units as u\n",
    "from matplotlib import cm\n",
    "from chromatic import get_phoenix_photons, get_planck_photons, version\n",
    "import astropy.constants as con\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import curve_fit\n",
    "import emcee\n",
    "import corner\n",
    "import speclite as speclite\n",
    "from matplotlib.artist import Artist\n",
    "from speclite import filters\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (12, 7),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "plt.rcParams.update(params)\n",
    "plt.style.use('seaborn-deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24cc0a-86c3-4fe3-897e-752b8b0cb021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quickfit_chisq(parameters, extras, **kwargs):\n",
    "    \n",
    "    Tspec = parameters\n",
    "    rwave, rflux, runc = extras\n",
    "    \n",
    "    if Tspec < 2350.:\n",
    "        Tspec = 2350.\n",
    "    if Tspec > 5000.:\n",
    "        Tspec = 5000.\n",
    "    \n",
    "    PHOENIX = get_phoenix_photons(temperature=float(Tspec), wavelength = rwave,logg=4.4, metallicity=0.0)[1]\n",
    "    model = PHOENIX/np.median(PHOENIX)\n",
    "    chisq = np.nansum((rflux-model)**2/(runc)**2)\n",
    "\n",
    "    return chisq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5a269-8fb3-48e1-be71-3d7b3187b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_clip_rainbow(rainbow, nsigma=5, **kwargs):\n",
    "    \n",
    "    #define some of the arrays\n",
    "    r = rainbow\n",
    "    unclipped_data = r.flux\n",
    "    unclipped_err = r.uncertainty\n",
    "    error_list = [None]*len(r.time)\n",
    "    function_to_minimize = quickfit_chisq\n",
    "\n",
    "    #loop through each time point\n",
    "    for i in tqdm(range(len(r.time))):\n",
    "        \n",
    "        initial_parameter_guess = [3750.5]\n",
    "        extras = [r.wavelength,unclipped_data[:,i],unclipped_err[:,i]]\n",
    "        results = minimize(function_to_minimize, initial_parameter_guess, extras)\n",
    "        _Tspec = results['x']\n",
    "        if _Tspec < 2350.:\n",
    "            _Tspec = 2350.\n",
    "        if _Tspec > 5000.:\n",
    "            _Tspec = 5000.\n",
    "        print(f'Initial guess was {initial_parameter_guess}')\n",
    "        print(f'Optimized Tspec is {int(_Tspec)}')\n",
    "        PHOENIX = get_phoenix_photons(temperature=float(_Tspec), wavelength = r.wavelength,logg=4.4, metallicity=0.0)[1]\n",
    "        preclip_model = PHOENIX/np.median(PHOENIX)\n",
    "        print('calculating initial chi^2...')\n",
    "        chisq = np.nansum((unclipped_data[:,i]-preclip_model)**2/(unclipped_err[:,i])**2)\n",
    "        unclipped_chisq = chisq/(len(unclipped_data[:,0])-1)\n",
    "        err_kludge = np.sqrt(unclipped_chisq)\n",
    "        print(f'initial reduced chi^2: {unclipped_chisq:.1f}')\n",
    "        print(f'initial error factor: {err_kludge:.1f}')\n",
    "        print('-----------------')\n",
    "        print(f'clipping emission lines...')\n",
    "        points_to_keep = ( (unclipped_data[:,i]-preclip_model)/(unclipped_err[:,i]*err_kludge) < 2.0 )\n",
    "        r.wavelike[\"ok\"] = points_to_keep\n",
    "        clipped = r.trim(just_edges=False)\n",
    "        print('----------------------------------')\n",
    "\n",
    "        print('calculating new model and chi^2...')\n",
    "        extras = [clipped.wavelength,clipped.flux[:,i],clipped.uncertainty[:,i]]\n",
    "        results = minimize(function_to_minimize, initial_parameter_guess, extras)\n",
    "        Tspec = results['x']\n",
    "        if Tspec < 2350.:\n",
    "            Tspec = 2350.\n",
    "        if Tspec > 5000.:\n",
    "            Tspec = 5000.\n",
    "        print(f'Initial guess was {initial_parameter_guess}')\n",
    "        print(f'Optimized Tspec is {int(Tspec)}')\n",
    "        PHOENIX = get_phoenix_photons(temperature=float(Tspec), wavelength = clipped.wavelength,logg=4.4, metallicity=0.0)[1]\n",
    "        model = PHOENIX/np.median(PHOENIX)\n",
    "        chisq = np.nansum((clipped.flux[:,i]-model)**2/(clipped.uncertainty[:,i])**2)\n",
    "        reduced_chisq = chisq/(len(clipped.wavelength)-1)\n",
    "        err_kludge = np.sqrt(reduced_chisq)\n",
    "        print(f'updated reduced chi^2: {reduced_chisq:.1f}')\n",
    "        print(f'error factor: {err_kludge:.1f}')\n",
    "        print('-----------------')\n",
    "        print(f'clipping {nsigma}-sigma outliers...')\n",
    "        points_to_keep = ( np.abs(clipped.flux[:,i]-model)/(clipped.uncertainty[:,i]*err_kludge) <= nsigma )\n",
    "        clipped.wavelike[\"ok\"] = points_to_keep\n",
    "        clipped = clipped.trim(just_edges=False)\n",
    "        print('----------------------------------')\n",
    "        \n",
    "        print('calculating another model and chi^2...')\n",
    "        extras = [clipped.wavelength,clipped.flux[:,i],clipped.uncertainty[:,i]]\n",
    "        results = minimize(function_to_minimize, initial_parameter_guess, extras)\n",
    "        Tspec = results['x']\n",
    "        if Tspec < 2350.:\n",
    "            Tspec = 2350.\n",
    "        if Tspec > 5000.:\n",
    "            Tspec = 5000.\n",
    "        print(f'Initial guess was {initial_parameter_guess}')\n",
    "        print(f'Optimized Tspec is {int(Tspec)}')\n",
    "        PHOENIX = get_phoenix_photons(temperature=float(Tspec), wavelength = clipped.wavelength,logg=4.4, metallicity=0.0)[1]\n",
    "        model = PHOENIX/np.median(PHOENIX)\n",
    "        chisq = np.nansum((clipped.flux[:,i]-model)**2/(clipped.uncertainty[:,i])**2)\n",
    "        reduced_chisq = chisq/(len(clipped.wavelength)-1)\n",
    "        err_kludge = np.sqrt(reduced_chisq)\n",
    "        print(f'updated reduced chi^2: {reduced_chisq:.1f}')\n",
    "        print(f'error factor: {err_kludge:.1f}')\n",
    "        print('-----------------')\n",
    "        print(f'clipping points with error > 20% ...')\n",
    "        err_outliers = ( clipped.uncertainty*err_kludge < 0.2 )\n",
    "        clipped.wavelike[\"ok\"] = err_outliers[:,i]\n",
    "        final = clipped.trim(just_edges=False)\n",
    "        print('----------------------------------')\n",
    "        \n",
    "        print('calculating a (hopefully final) model and chi^2...')\n",
    "        extras = [final.wavelength,final.flux[:,i],final.uncertainty[:,i]]\n",
    "        results = minimize(function_to_minimize, initial_parameter_guess, extras)\n",
    "        Tspec = results['x']\n",
    "        if Tspec < 2350.:\n",
    "            Tspec = 2350.\n",
    "        if Tspec > 5000.:\n",
    "            Tspec = 5000.\n",
    "        print(f'Initial guess was {initial_parameter_guess}')\n",
    "        print(f'FINAL Optimized Tspec is {int(Tspec)}')\n",
    "        PHOENIX = get_phoenix_photons(temperature=float(Tspec), wavelength = final.wavelength,logg=4.4, metallicity=0.0)[1]\n",
    "        finalmodel = PHOENIX/np.median(PHOENIX)\n",
    "        chisq = np.nansum((final.flux[:,i]-finalmodel)**2/(final.uncertainty[:,i])**2)\n",
    "        reduced_chisq = chisq/(len(final.wavelength)-1)\n",
    "        err_kludge = np.sqrt(reduced_chisq)\n",
    "        error_list[i] = err_kludge\n",
    "        final.uncertainty = final.uncertainty*err_kludge\n",
    "        print(f'updated reduced chi^2: {reduced_chisq:.1f}')\n",
    "        print(f'error factor: {err_kludge:.1f}')\n",
    "        print('----------------------------------')\n",
    "\n",
    "        sanity_check = np.nansum((final.flux[:,i]-finalmodel)**2/(final.uncertainty[:,i]*err_kludge)**2)\n",
    "        should_be_1 = sanity_check/(len(final.wavelength)-1)\n",
    "        ##########################################\n",
    "\n",
    "        print('plotting...')\n",
    "        label=f'Order {order} | BJD {r.time[i].value:.1f} | err kludge: {error_list[i]:0.1f} | reduced chisq: {should_be_1:.2f}'\n",
    "        fig, axs = plt.subplots(2,2,figsize=(12,10),sharex=True)\n",
    "        fig.suptitle(label,fontsize=20)\n",
    "\n",
    "        ax1 = axs[0,0]\n",
    "        ax2 = axs[1,0]\n",
    "        ax3 = axs[0,1]\n",
    "        ax4 = axs[1,1]\n",
    "\n",
    "        # Upper left plot, the pre-clipped data + model\n",
    "        ax1.errorbar(r.wavelength.value,\n",
    "                     unclipped_data[:,i],\n",
    "                     yerr=unclipped_err[:,i],color='red',alpha=0.7,\n",
    "                     zorder=-10,label='pre-clipped data',fmt='',capsize=0)\n",
    "        ax1.plot(r.wavelength.value,preclip_model,alpha=1,\n",
    "                     color='black',zorder=100,label=f'{int(_Tspec)} K PHOENIX model')\n",
    "        ax1.set_title('Pre-clipped',fontsize=16)\n",
    "        ax1.set_ylim(0,1.5)\n",
    "        ax1.set_ylabel('normalized flux',fontsize=16)\n",
    "        ax1.legend(loc='lower right')\n",
    "\n",
    "        # Lower left plot, residuals on original data and model\n",
    "        ax2.errorbar(r.wavelength.value,\n",
    "                     (unclipped_data[:,i]-preclip_model)/unclipped_err[:,i],\n",
    "                     yerr=unclipped_err[:,i],color='black',fmt='',capsize=0,zorder=100)\n",
    "        #ax2.set_ylim(-nsigma,nsigma)\n",
    "        ax2.set_xlim(r.wavelength[0].value,r.wavelength[-1].value)\n",
    "        ax2.set_xlabel(r'Wavelength ($\\mu$)',fontsize=16)\n",
    "        ax2.set_ylabel(r'Residual ($\\sigma$)',fontsize=16)\n",
    "        ax2.set_title('Residuals',fontsize=16)\n",
    "        ax2.set_ylim(-10,10)\n",
    "        ax2.axhspan(-1,1,color='red',alpha=0.2,zorder=10)\n",
    "        ax2.axhspan(-2,2,color='green',alpha=0.2,zorder=0)\n",
    "        ax2.axhspan(-3,3,color='gray',alpha=0.3,zorder=-10)\n",
    "\n",
    "        # Upper right plot, the clipped data + model\n",
    "        ax3.errorbar(final.wavelength.value,\n",
    "                     final.flux[:,i],yerr=final.uncertainty[:,i],alpha=0.7,\n",
    "                     color='teal',zorder=10,label='post-clipped data',fmt='',capsize=0)\n",
    "        ax3.set_title('Post-clipped',fontsize=16)\n",
    "        ax3.set_ylim(0,1.5)\n",
    "        ax3.plot(final.wavelength.value,finalmodel,alpha=1,\n",
    "                     color='black',zorder=100,label=f'{int(Tspec)} K PHOENIX model')\n",
    "        ax3.legend(loc='lower right')\n",
    "\n",
    "        # Lower right plot, the final residuals\n",
    "        ax4.errorbar(final.wavelength.value,\n",
    "                 (final.flux[:,i]-finalmodel)/final.uncertainty[:,i],\n",
    "                 yerr=final.uncertainty[:,i],color='black',fmt='',capsize=0,zorder=100)\n",
    "        ax4.set_ylim(-nsigma,nsigma)\n",
    "        ax4.set_xlim(r.wavelength[0].value,r.wavelength[-1].value)\n",
    "        ax4.set_xlabel(r'Wavelength ($\\mu$)',fontsize=16)\n",
    "        ax4.set_title('Residuals',fontsize=16)\n",
    "        ax4.axhspan(-1,1,color='red',alpha=0.2,zorder=10)\n",
    "        ax4.axhspan(-2,2,color='green',alpha=0.2,zorder=0)\n",
    "        ax4.axhspan(-3,3,color='gray',alpha=0.3,zorder=-10)\n",
    "        #ax4.legend(loc='upper right')\n",
    "        plt.savefig(f'figs/nres_sigmaclip/{visit}_order{order}_{i}_sigmaclip_timespec.pdf')\n",
    "        plt.show()\n",
    "        \n",
    "    return error_list, final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e7bf5-4038-4dc3-af1d-4bd8bfc9863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(order = 53,\n",
    "               visit = 'fall',\n",
    "               vshift=-8.7,\n",
    "               dw=0.05*u.nm):\n",
    "    \"\"\"\n",
    "    Load in and process NRES spectra\n",
    "    \"\"\"\n",
    "    \n",
    "    #define visit-specific parameters (why not use dicts? good question)\n",
    "    if visit == 'fall':\n",
    "        data_path = 'data/NRES/fall_2021_spectra/*e92-1d.fits.fz'\n",
    "        phot_amplitudes = np.array([0.054,0.067,0.049])\n",
    "        phot_errs = np.array([0.006,0.006,0.004])\n",
    "        phase = 2.992 - np.pi/2.\n",
    "        T0 = (59455.48 + 2400000.5)\n",
    "        edges = np.array([2459451.0,2459452.0,2459454.0,2459457.0,2459459.0,2459460.0,2459461.0])*u.day\n",
    "        _ntimes = len(edges)\n",
    "        \n",
    "    if visit == 'spring':\n",
    "        data_path = 'data/NRES/spring_2022_spectra/*e92-1d.fits.fz'\n",
    "        phot_amplitudes = np.array([0.07,0.071])\n",
    "        phot_errs = np.array([0.004,0.004])\n",
    "        phase = 2.87 - np.pi/2.\n",
    "        T0 = (59455.48 + 2400000.5) + (27.*8.46)\n",
    "        edges = np.array([2459680.5,2459681.5,2459682.5,\n",
    "                          2459683.5,2459684.5,2459685.5,\n",
    "                          2459686.5,2459687.5,2459688.5])*u.day\n",
    "        _ntimes = len(edges)\n",
    "    \n",
    "    #create the rainbow object and apply the velocity shift\n",
    "    r = Rainbow(data_path, format='nres', order=order)\n",
    "    shifted_r = r.align_wavelengths().shift(vshift *u.km/u.s)\n",
    "\n",
    "    #correct for atmospheric transmission from skycalc outputs\n",
    "    transmission_data = np.loadtxt('data/transmission_comp.dat')\n",
    "    mol_wave = transmission_data[:,0]*(1e-3) * u.micron\n",
    "    mol_data = transmission_data[:,1]\n",
    "    this_orders_tellurics = bintogrid(mol_wave.value,mol_data,newx=shifted_r.wavelength.value,visualize=False)\n",
    "    transparent_wavelengths = (this_orders_tellurics['y'] > 0.995)\n",
    "    shifted_r.wavelike[\"ok\"] = transparent_wavelengths\n",
    "\n",
    "    #bin the rainbow so the clipping doesn't take a thousand years\n",
    "    preclipped_rainbow = shifted_r.trim(just_edges=False).bin(dw=dw,time_edges = edges,ntimes = _ntimes,\n",
    "                                                                 minimum_points_per_bin=1)\n",
    "\n",
    "    #run the sigma clipping function to return a final processed rainbow\n",
    "    this_orders_errbar,processed_r = sigma_clip_rainbow(rainbow=preclipped_rainbow,nsigma=3)\n",
    "    \n",
    "    return processed_r, phot_amplitudes, phot_errs, phase, T0, this_orders_errbar,this_orders_tellurics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957d4bda-58e8-4d05-a50e-0ddb11cd12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_amplitude_model(parameters=[0.15,0.06,3000,3800],\n",
    "                         plot=False,\n",
    "                         visit='fall',\n",
    "                         **kwargs):\n",
    "    \n",
    "    bandpass=np.linspace(3500.,8500.,300)*u.angstrom\n",
    "    sdss_responses = speclite.filters.load_filters('sdss2010-g','sdss2010-r','sdss2010-i')\n",
    "    response_g = sdss_responses[0].interpolator(bandpass)\n",
    "    response_r = sdss_responses[1].interpolator(bandpass)\n",
    "    response_i = sdss_responses[2].interpolator(bandpass)\n",
    "\n",
    "    f_spot,df_spot,T_spot,T_amb = parameters\n",
    "\n",
    "    ds_spot = get_phoenix_photons(temperature=float(T_spot), wavelength = bandpass,logg=4.4, metallicity=0.0)[1]\n",
    "    ds_amb = get_phoenix_photons(temperature=float(T_amb), wavelength = bandpass,logg=4.4, metallicity=0.0)[1]\n",
    "    d_lambda = (bandpass[1]-bandpass[0])\n",
    "\n",
    "    ds_over_s = -df_spot*((1.-ds_spot/ds_amb) / (1.-f_spot*(1.-ds_spot/ds_amb)))\n",
    "    semi_amplitude = np.abs(ds_over_s)\n",
    "\n",
    "    numerator = np.nansum(semi_amplitude*response_g*d_lambda)\n",
    "    denominator = np.nansum(response_g*d_lambda)\n",
    "    gp = numerator/denominator\n",
    "\n",
    "    numerator = np.nansum(semi_amplitude*response_r*d_lambda)\n",
    "    denominator = np.nansum(response_r*d_lambda)\n",
    "    rp = numerator/denominator\n",
    "\n",
    "    numerator = np.nansum(semi_amplitude*response_i*d_lambda)\n",
    "    denominator = np.nansum(response_i*d_lambda)\n",
    "    ip = numerator/denominator\n",
    "\n",
    "    if visit == 'spring':\n",
    "        model = np.array([gp,rp])\n",
    "        model_coords = [4750,6200]\n",
    "    else:\n",
    "        model = np.array([gp,rp,ip])\n",
    "        model_coords = [4750,6200,7550]\n",
    "\n",
    "    if plot:\n",
    "        fig, ax1 = plt.subplots(figsize=(14,8))\n",
    "        chisq = np.nansum((photometry_amplitudes-model)**2/(photometry_errs**2))\n",
    "        reduced_chisq = chisq/(len(photometry_amplitudes)-1)\n",
    "        kludge = np.sqrt(reduced_chisq)\n",
    "        title_label=f'Order {order} | fspot={f_spot:.2f}+/-{df_spot:.2f}| Tspot={int(T_spot/10)*10} | Tamb={int(T_amb/10)*10} | err kludge: {kludge:0.1f} | reduced chisq: {reduced_chisq:.2f}'\n",
    "        fig.suptitle(title_label,fontsize=20)\n",
    "\n",
    "        ax1.set_xlabel(r'Wavelength $\\AA$',fontsize=20)\n",
    "        ax1.set_ylabel(r'$\\frac{\\Delta S(\\lambda)}{S_{avg}}$',fontsize=16)\n",
    "        ax1.plot(bandpass, semi_amplitude,zorder=100)\n",
    "        ax1.scatter(model_coords,model,color='red',zorder=100,label='model value')\n",
    "        ax1.errorbar(model_coords,photometry_amplitudes,photometry_errs,color='k',\n",
    "                     label='Measured Variability',fmt='o')\n",
    "        ax1.set_xlim(3500,8500)\n",
    "        ax1.set_ylim(0,0.1)\n",
    "        ax1.legend(loc='upper right')\n",
    "\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.fill_between(bandpass.value, bandpass.value*0, response_g,color='orange',\n",
    "                         zorder=-100,label='SDSS g filter response',alpha=0.3)\n",
    "        ax2.fill_between(bandpass.value, bandpass.value*0, response_r,color='teal',\n",
    "                         zorder=-100,label='SDSS r filter response',alpha=0.3)\n",
    "        ax2.fill_between(bandpass.value, bandpass.value*0, response_i,color='purple',\n",
    "                         zorder=-100,label='SDSS i filter response',alpha=0.3)\n",
    "        ax2.set_ylabel('Filter Response',fontsize=16)\n",
    "        ax2.set_ylim(0,0.6)\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.savefig(f'figs/photometric_variability/bestfits/{visit}_order{order}_bestfit_photovariability_timespec.pdf')\n",
    "        plt.show()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e9b0e-82e6-4271-9fc9-be565495f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_spectrum_model(parameters=[0.15,0.06,3000,3800],\n",
    "                       plot=False,\n",
    "                       **kwargs):\n",
    "\n",
    "    f_spot,df_spot,T_spot, T_amb = parameters\n",
    "    combined = f_spot*spot_spec + (1.-f_spot)*amb_spec\n",
    "    combined_spec = combined/np.nanmedian(combined)\n",
    "    \n",
    "    chisq = np.nansum((nres_avg_1dspec-combined_spec)**2/(nres_avg_1derr**2))\n",
    "    reduced_chisq = chisq/(len(nres_avg_1dspec)-4)\n",
    "    kludge = np.sqrt(reduced_chisq)\n",
    "    \n",
    "    if plot:\n",
    "        title_label=f'Order {order} | fspot={f_spot:.2f}+/-{df_spot:.2f}| Tspot={int(T_spot/10)*10} | Tamb={int(T_amb/10)*10} | err kludge: {kludge:0.1f} | reduced chisq: {reduced_chisq:.2f}'\n",
    "      \n",
    "        #now set up the figure(s)\n",
    "        fig, [ax0,ax1,ax2] = plt.subplots(3,1,figsize=(12,18),sharex=True)\n",
    "        fig.suptitle(title_label,fontsize=18)\n",
    "        \n",
    "        ax0.plot(data_wave, combined_spec, label = 'Spot model',color='k',alpha=0.9,zorder=100)\n",
    "        ax0.errorbar(data_wave, nres_avg_1dspec, yerr=nres_avg_1derr, zorder=-1000,color='teal',label='NRES time-averaged spectrum',fmt='',alpha=0.9)\n",
    "        ax0.set_ylim(0.5,1.5)\n",
    "        ax0.set_ylabel('Relative Flux',fontsize=16)\n",
    "        ax0.legend(loc='lower right')\n",
    "\n",
    "        ax1.errorbar(data_wave,(nres_avg_1dspec-combined_spec)/(nres_avg_1derr),\n",
    "                     yerr=(nres_avg_1derr),label='Residual',color='k',zorder=100)\n",
    "        ax1.set_ylabel(r'$\\sigma$',fontsize=16)\n",
    "        ax1.set_ylim(-5,5)\n",
    "        ax1.legend(loc='lower right')\n",
    "        ax1.axhspan(-1,1,color='red',alpha=0.2,zorder=10)\n",
    "        ax1.axhspan(-2,2,color='green',alpha=0.2,zorder=0)\n",
    "        ax1.axhspan(-3,3,color='gray',alpha=0.3,zorder=-10)\n",
    "        \n",
    "        ax2.plot(this_orders_tellurics['x'], this_orders_tellurics['y'],label='Telluric Spectrum')\n",
    "        ax2.axhline(0.995,color='red',label='0.995 cutoff')\n",
    "        ax2.set_xlabel(r'Wavelength ($\\mu$)',fontsize=16)\n",
    "        ax2.set_ylabel('Molecular Transmission Fraction',fontsize=16)\n",
    "        ax2.legend(loc='upper right')\n",
    "        ax2.set_ylim(0.95,1.01)\n",
    "        ax2.set_yscale('log')\n",
    "        ax2.set_xlim(this_orders_tellurics['x'][0],this_orders_tellurics['x'][-1])\n",
    "\n",
    "        plt.savefig(f'figs/avg_spectra_models/bestfits/{visit}_order{order}_bestfit_avgspectrum_timespec.pdf')\n",
    "\n",
    "    return combined_spec,chisq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5942c4-904e-4ff5-9d27-b82aa0c1933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_spectrum_model(parameters=[0.15,0.06,3000,3800],\n",
    "                        T_rot = 4.86, # days\n",
    "                        plot=False,\n",
    "                        **kwargs):\n",
    "\n",
    "    f_spot,df_spot,T_spot, T_amb = parameters\n",
    "\n",
    "    combined = f_spot*spot_spec + (1.-f_spot)*amb_spec\n",
    "    S_avg_model = combined/np.median(combined)\n",
    "    contrast = (1.-spot_spec/amb_spec)\n",
    "    dS_over_S = np.abs(-df_spot*( contrast / (1.-f_spot*(contrast))))\n",
    "\n",
    "    spec_model = np.ones_like(nres_rainbow.flux)\n",
    "    nres_spec_comparison = np.ones_like(nres_rainbow.flux)\n",
    "\n",
    "    for i in range(len(data_times)):\n",
    "        S_t_model = 0.0\n",
    "        S_t_model = S_avg_model * ( 1. + dS_over_S * np.cos(2.0*np.pi*data_times[i].value/T_rot + phase) )\n",
    "        spec_model[:,i] = S_t_model/np.median(S_t_model)\n",
    "        nres_spec_comparison[:,i] = nres_rainbow.flux[:,i]/nres_avg_1dspec\n",
    "        \n",
    "    chisq = np.nansum((nres_rainbow.flux - spec_model)**2/(nres_rainbow.uncertainty)**2)\n",
    "    reduced_chisq = chisq/(len(nres_rainbow.wavelength)*len(data_times)-4)\n",
    "    kludge = np.sqrt(reduced_chisq)\n",
    "\n",
    "    if plot:\n",
    "\n",
    "        model_data_times = np.linspace(data_times[0].value-1,data_times[-1].value+1,1000)\n",
    "        cmap = cm.get_cmap('cividis', len(data_times))\n",
    "        colormap = cmap(np.linspace(0, 1, len(data_times)))\n",
    "\n",
    "        fig, axs = plt.subplots(2,3,figsize=(18,10))\n",
    "        title_label=f'Order {order} | fspot={f_spot:.2f}+/-{df_spot:.2f}| Tspot={int(T_spot/10)*10} | Tamb={int(T_amb/10)*10} | err kludge: {kludge:0.1f} | reduced chisq: {reduced_chisq:.2f}'\n",
    "        fig.suptitle(title_label,fontsize=20)\n",
    "\n",
    "        ax1 = axs[0,0]\n",
    "        ax2 = axs[1,0]\n",
    "        ax3 = axs[0,1]\n",
    "        ax4 = axs[1,1]\n",
    "        ax5 = axs[0,2]\n",
    "        ax6 = axs[1,2]\n",
    "\n",
    "        for i in range(len(data_times)):\n",
    "            ax3.errorbar(data_wave,nres_rainbow.flux[:,i],yerr=nres_rainbow.uncertainty[:,i],alpha=0.6,\n",
    "                         color=colormap[i],fmt='')\n",
    "            ax4.plot(data_wave,(spec_model[:,i]-nres_rainbow.flux[:,i])/nres_rainbow.uncertainty[:,i],\n",
    "                     alpha=0.6,color=colormap[i])\n",
    "        \n",
    "        ax1.plot(data_wave,(spot_spec/np.median(spot_spec)-amb_spec/np.median(amb_spec))/(T_amb-T_spot),color='k')\n",
    "        ax1.set_title(r'Spot model dS/dT',fontsize=16)\n",
    "        #ax1.set_ylim(0.85,1.15)\n",
    "        ax1.set_xlabel(r'Wavelength ($\\mu$)',fontsize=16)\n",
    "        ax1.set_xlim(this_orders_tellurics['x'][0],this_orders_tellurics['x'][-1])\n",
    "        \n",
    "        ax2.plot(data_wave,dS_over_S)\n",
    "        ax2.set_title(r'Spot model dS/S',fontsize=16)\n",
    "        ax2.set_xlim(this_orders_tellurics['x'][0],this_orders_tellurics['x'][-1])\n",
    "\n",
    "        ax3.plot(data_wave, np.median(spec_model,axis=1),color='k',zorder=10,label='median model spectrum')\n",
    "        ax3.set_title('NRES data',fontsize=16)\n",
    "        ax3.set_ylim(0.5,1.5)\n",
    "        ax3.set_xlabel(r'Wavelength ($\\mu$)',fontsize=16)\n",
    "        ax3.set_xlim(this_orders_tellurics['x'][0],this_orders_tellurics['x'][-1])\n",
    "        ax3.legend()\n",
    "           \n",
    "        ax4.set_title(r'Residuals ',fontsize=16)\n",
    "        ax4.set_xlabel(r'Wavelength ($\\mu$)',fontsize=16)\n",
    "        ax4.set_ylabel(r'$\\sigma$',fontsize=16)\n",
    "        ax4.set_xlim(this_orders_tellurics['x'][0],this_orders_tellurics['x'][-1])\n",
    "\n",
    "        speccompplot = ax5.imshow(np.transpose(nres_spec_comparison),aspect='auto',cmap='Reds')\n",
    "        ax5.set_title(r'NRES S($\\lambda$,t)/S($\\lambda$)',fontsize=16)\n",
    "        ax5.set_ylabel('Observation #',fontsize=16)\n",
    "        ax5.set_xlabel('Wavelength array #',fontsize=16)\n",
    "        plt.colorbar(speccompplot, ax = ax5)\n",
    "        \n",
    "        specplot= ax6.imshow(np.transpose(spec_model),aspect='auto',cmap='Reds')\n",
    "        ax6.set_title('PHOENIX Model Spectra',fontsize=16)\n",
    "        ax6.set_ylabel('Observation #',fontsize=16)\n",
    "        ax6.set_xlabel('Wavelength array #',fontsize=16)\n",
    "        plt.colorbar(specplot, ax = ax6) \n",
    "\n",
    "        plt.savefig(f'figs/time_domain_spectra_models/bestfits/{visit}_order{order}_bestfit_timespectra_timespec.pdf')\n",
    "        plt.show()\n",
    "\n",
    "    return spec_model,chisq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aada8de-3651-4996-9c72-c6ad76dce9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprob(parameters=[0.15,0.06,3000,3800],\n",
    "           plot = False, **kwargs):\n",
    "\n",
    "    f_spot,df_spot,T_spot,T_amb = parameters\n",
    "\n",
    "    if (0.0<=f_spot<=0.5) and (0.<=df_spot<f_spot) and (2300.0<=T_spot<=4000.0) and (2300.0<=T_amb<=4500.0):\n",
    "\n",
    "        ln_like=0\n",
    "\n",
    "        spot_spec = get_phoenix_photons(temperature=float(T_spot), wavelength = data_wave,logg=4.4, metallicity=0.0)[1]\n",
    "        amb_spec = get_phoenix_photons(temperature=float(T_amb), wavelength = data_wave,logg=4.4, metallicity=0.0)[1]\n",
    "\n",
    "        \"S_t calculations\"\n",
    "        S_t_model,chisq_time_spec = time_spectrum_model(parameters,plot=plot)\n",
    "        ln_like += (np.nansum(1/np.sqrt(2*np.pi*(nres_rainbow.uncertainty))) - 0.5*chisq_time_spec)\n",
    "\n",
    "    else:\n",
    "        ln_like = -np.inf\n",
    "\n",
    "    return ln_like\n",
    "\n",
    "def negative_lnprob(parameters,**kwargs):\n",
    "    return -lnprob(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6be143-0cc9-44cd-8739-5030d130a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mcmc(order=53,\n",
    "            nsteps=1000,\n",
    "            visit='fall',\n",
    "            vshift=None,\n",
    "            dw=0.05*u.nm,\n",
    "            **kwargs):\n",
    "    \n",
    "    variables =  initialize(order=order,visit=visit,vshift=vshift,dw=dw)\n",
    "    nres_rainbow = variables[0]\n",
    "    photometry_amplitudes = variables[1]\n",
    "    photometry_errs = variables[2]\n",
    "    phase = variables[3]\n",
    "    T0 = init_vars[4]\n",
    "    this_orders_errbar = variables[5]\n",
    "    this_orders_tellurics = variables[6]\n",
    "    \n",
    "    _1dof = len(nres_rainbow.wavelength)-4\n",
    "    _2dof = len(nres_rainbow.wavelength)*len(nres_rainbow.time)-4\n",
    "    init_st_model, time_spec_chisq = time_spectrum_model(visit=visit)\n",
    "    time_spec_kludge = np.sqrt(time_spec_chisq/(_2dof))\n",
    "    init_savg_model, avg_spec_chisq = avg_spectrum_model(visit=visit)\n",
    "    avg_spec_kludge = np.sqrt(avg_spec_chisq/(_1dof))\n",
    "    print(f'multipling avg spectrum uncertainty by {avg_spec_kludge} and the 2d uncertainty array by {time_spec_kludge}')\n",
    "    \n",
    "    nres_avg_1dspec = nres_rainbow.get_average_spectrum()\n",
    "    nres_avg_1derr = np.nanmedian(nres_rainbow.uncertainty,axis=1)*avg_spec_kludge\n",
    "    nres_rainbow.uncertainty = nres_rainbow.uncertainty*time_spec_kludge\n",
    "    data_times = nres_rainbow.timelike['time']\n",
    "    data_wave = nres_rainbow.wavelength\n",
    "\n",
    "    # intialize some walkers\n",
    "    ndim, nwalkers = 4, 100\n",
    "    burnin = int(0.3*nsteps)\n",
    "    \n",
    "    fitted_parameters=[0.15,0.06,3000,3800]\n",
    "    # these are initial parameters\n",
    "    fspot_init = np.random.uniform(fitted_parameters[0]-0.1, fitted_parameters[0]+0.1, nwalkers)\n",
    "    dfspot_init = np.random.uniform(fitted_parameters[1]-0.05, fitted_parameters[1]+0.05, nwalkers)\n",
    "    Tspot_init = np.random.uniform(fitted_parameters[2]-300, fitted_parameters[2]+300, nwalkers)\n",
    "    Tamb_init = np.random.uniform(fitted_parameters[3]-100, fitted_parameters[3]+100, nwalkers)\n",
    "\n",
    "    p0 = np.transpose([fspot_init, dfspot_init, Tspot_init, Tamb_init])\n",
    "\n",
    "    # set up file saving for the samples when finished\n",
    "    filename = f\"data/{visit}_order{order}_{nsteps}steps_samples_timespec.h5\"\n",
    "    backend = emcee.backends.HDFBackend(filename)\n",
    "    backend.reset(nwalkers, ndim)\n",
    "\n",
    "    # Initialize the sampler\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, backend=backend)\n",
    "\n",
    "    # run the sampler\n",
    "    result = sampler.run_mcmc(p0, nsteps)\n",
    "\n",
    "    samples = sampler.chain[:, burnin:, :].reshape((-1, ndim)).T\n",
    "\n",
    "    fspot_sam, dfspot_sam, Tspot_sam, Tamb_sam = samples\n",
    "\n",
    "    sig1_fspot = np.percentile(fspot_sam, [16., 50., 95.])\n",
    "    sig1_dfspot = np.percentile(dfspot_sam, [16., 50., 95.])\n",
    "    sig1_Tspot = np.percentile(Tspot_sam, [16., 50., 95.])\n",
    "    sig1_Tamb = np.percentile(Tamb_sam, [16., 50., 95.])\n",
    "\n",
    "    # Define the 50% percentile and 1-sigma interval parameter values from the samples\n",
    "    best_params = np.array([sig1_fspot[1], sig1_dfspot[1], sig1_Tspot[1], sig1_Tamb[1]])\n",
    "    best_params_err_lower = best_params-[sig1_fspot[0], sig1_dfspot[0], sig1_Tspot[0], sig1_Tamb[0]]\n",
    "    best_params_err_higher = [sig1_fspot[2], sig1_dfspot[2], sig1_Tspot[2], sig1_Tamb[2]]-best_params\n",
    "    variable_names = [r'f$_{\\rm{spot}}$',r'df$_{\\rm{spot}}$',r'T$_{\\rm{spot}}$',r'T$_{\\rm{amb}}$']\n",
    "    normie_names = ['fspot','dfspot','Tspot','Tamb']\n",
    "    \n",
    "    # Print out the results\n",
    "    for i in range(ndim):\n",
    "        print(f'{normie_names[i]} = {best_params[i]:.2f} + {best_params_err_higher[i]:.2f} - {best_params_err_lower[i]:.2f}')\n",
    "    final_avg_Teff = (best_params[0]*best_params[2]**4 + (1-best_params[0])*best_params[3]**4)**(1/4)\n",
    "    print('Teff = ',int(final_avg_Teff/10)*10)\n",
    "\n",
    "    #make the corner plot\n",
    "    figure = corner.corner(samples.T, labels=variable_names,\n",
    "                           quantiles=[0.16, 0.5, 0.84],\n",
    "                           show_titles=True, title_kwargs={\"fontsize\": 16})\n",
    "\n",
    "    # Extract the axes, loop through to set all the limits\n",
    "    axes = np.array(figure.axes).reshape((ndim, ndim))\n",
    "    for yi in range(ndim):\n",
    "        ax = axes[yi, 0]\n",
    "        ax.set_xlim(0,0.5)\n",
    "        ax = axes[yi, 1]\n",
    "        ax.set_xlim(0,0.25)\n",
    "        ax = axes[yi, 2]\n",
    "        ax.set_xlim(2300,4000)\n",
    "        ax = axes[yi, 3]\n",
    "        ax.set_xlim(3600,4500)\n",
    "    plt.savefig(f'figs/corner_plots/{visit}_order{order}_corner_timespec.pdf')\n",
    "    \n",
    "    # Plot models\n",
    "    semi_amplitude_model(parameters = best_params, plot=True)\n",
    "    avg_spectrum_model(parameters = best_params, plot=True)\n",
    "    time_spectrum_model(parameters=best_params, plot = True)\n",
    "    \n",
    "    # Plot samples\n",
    "    fig, axs = plt.subplots(2,2,figsize=(10,10))\n",
    "    ax1 = axs[0,0]\n",
    "    ax2 = axs[1,0]\n",
    "    ax3 = axs[0,1]\n",
    "    ax4 = axs[1,1]\n",
    "    #plot dfspot vs fspot\n",
    "    ax1.scatter(dfspot_sam,fspot_sam,c=fspot_sam,cmap='BrBG',alpha=0.6,edgecolor=None)\n",
    "    ax1.plot(dfspot_sam,dfspot_sam)\n",
    "    ax1.set_ylabel(r'f$_{\\rm{spot}}$',fontsize=20)\n",
    "    ax1.set_ylim(0,0.5)\n",
    "    ax1.set_xlim(0,0.25)\n",
    "    #plt.colorbar(p1,ax=ax1)\n",
    "    \n",
    "    #plot dfspot vs log(Tspot/Tamb)\n",
    "    ax2.scatter(dfspot_sam,np.log(Tspot_sam/Tamb_sam),c=np.log(Tspot_sam/Tamb_sam),\n",
    "                cmap='BrBG',alpha=0.6,edgecolor=None)\n",
    "    ax2.set_xlabel(r'$\\Delta$ f$_{spot}$',fontsize=20)\n",
    "    ax2.set_ylabel(r'Log(T$_{\\rm{spot}}$/T$_{\\rm{amb}}$)',fontsize=20)\n",
    "    ax2.set_xlim(0,0.25)\n",
    "    ax2.set_ylim(-0.5,0)\n",
    "    #plt.colorbar(p2,ax=ax2)\n",
    "    \n",
    "    #plot fspot vs log(N), the number of spots\n",
    "    ax3.scatter(fspot_sam,np.log((fspot_sam/dfspot_sam)**2),c=np.log(Tspot_sam/Tamb_sam),\n",
    "                cmap='BrBG',alpha=0.6,edgecolor=None)\n",
    "    ax3.set_ylim(0,6)\n",
    "    ax3.set_xlim(0,0.5)\n",
    "    ax3.set_ylabel(r'Log(N$_{\\rm{spot}}$)',fontsize=20)\n",
    "    #ax3.set_yscale('log')\n",
    "    #plt.colorbar(p3,ax=ax3)\n",
    "    \n",
    "    #plot fspot vs log(f1), the filling factor of 1 spot\n",
    "    ax4.scatter(fspot_sam,np.log(dfspot_sam**2/fspot_sam),c=np.log(Tspot_sam/Tamb_sam),\n",
    "                cmap='BrBG',alpha=0.2,edgecolor=None)\n",
    "    ax4.set_xlabel(r'f$_{\\rm{spot}}$',fontsize=20)\n",
    "    ax4.set_xlim(0,0.5)\n",
    "    ax4.set_ylim(-6,0)\n",
    "    #ax4.set_yscale('log')\n",
    "    ax4.set_ylabel(r'Log(f$_1$)',fontsize=20)\n",
    "    #plt.colorbar(p4,ax=ax4)\n",
    "    \n",
    "    plt.savefig(f'figs/samples/{visit}_order{order}_plotsamples_timespec.png',dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9efbc84-7824-4374-a0f1-e89a2bb3275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set some params for model initialization\n",
    "order = 65\n",
    "visit = 'fall'\n",
    "vshift = -8.7\n",
    "dw = 0.05 * u.nm\n",
    "\n",
    "init_vars =  initialize(order=order,visit=visit,vshift=vshift,dw=dw)\n",
    "nres_rainbow = init_vars[0]\n",
    "photometry_amplitudes = init_vars[1]\n",
    "photometry_errs = init_vars[2]\n",
    "phase = init_vars[3]\n",
    "T0 = init_vars[4]\n",
    "this_orders_errbar = init_vars[5]\n",
    "this_orders_tellurics = init_vars[6]\n",
    "\n",
    "#define some global variables\n",
    "data_times = nres_rainbow.timelike['time']\n",
    "data_wave = nres_rainbow.wavelength\n",
    "nres_avg_1dspec = nres_rainbow.get_average_spectrum()\n",
    "nres_avg_1derr = np.nanmedian(nres_rainbow.uncertainty,axis=1)*2\n",
    "spot_spec = get_phoenix_photons(temperature=3000., wavelength = data_wave,logg=4.4, metallicity=0.0)[1]\n",
    "amb_spec = get_phoenix_photons(temperature=3800., wavelength = data_wave,logg=4.4, metallicity=0.0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314474ab-51af-4b3f-bbfa-531f0db18480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do_mcmc(order = order,\n",
    "#     nsteps = 10,\n",
    "#     visit=visit,\n",
    "#     vshift=-8.7,\n",
    "#     dw=dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92020e23-833b-49f4-97d3-973831268fe4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(53,90)):\n",
    "    order = int(i)\n",
    "    do_mcmc(order = order,\n",
    "            nsteps = 1000,\n",
    "            visit='fall',\n",
    "            vshift=-8.7,\n",
    "            dw=0.05*u.nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fef6e5-9fcb-4a64-81f0-1c311a75f271",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(53,90)):\n",
    "    do_mcmc(order = int(i),\n",
    "            nsteps = 1000,\n",
    "            visit='spring',\n",
    "            vshift=35.,\n",
    "            dw=0.05*u.nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e5fb7-e606-4050-85c2-64cd83749aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
